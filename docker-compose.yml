version: '3.9'

x-querybook-image: &querybook-image querybook-dev:latest
x-querybook-depends-on: &querybook-depends-on
#    mysql:
#        condition: service_healthy
    redis:
        condition: service_healthy
    elasticsearch:
        condition: service_healthy
x-querybook-volumes: &querybook-volumes
    # This is to sync in live code change
    - $PWD:/opt/querybook
    - $PWD/docs_website/static/changelog:/opt/querybook/querybook/static/changelog
    # See https://stackoverflow.com/questions/29181032/add-a-volume-to-docker-but-exclude-a-sub-folder
    - /opt/querybook/node_modules/
    # Make sure the build files don't leak back
    - /opt/querybook/dist/
    - $PWD/containers/bundled_querybook_config.yaml:/opt/querybook/querybook/config/querybook_config.yaml
    # - file:/opt/store/

services:
    web:
        container_name: querybook_web
        image: *querybook-image
        tty: true
        stdin_open: true
        # network_mode: 'host'
        command: './querybook/scripts/bundled_docker_run_web --initdb --initweb'
        ports:
            - '${PORT:-10001}:${PORT:-10001}'
        expose:
            - '${PORT:-10001}'
        environment:
            PORT: '${PORT:-10001}'
            APIPORT: '${APIPORT:-3000}'
            HOT_RELOAD: '${HOT_RELOAD:-true}'
        restart: 'always'
        volumes: *querybook-volumes
        depends_on: *querybook-depends-on
    worker:
        container_name: querybook_worker
        image: *querybook-image
        tty: true
        stdin_open: true
        command: './querybook/scripts/runservice worker -c 5'
        volumes: *querybook-volumes
        depends_on: *querybook-depends-on
    scheduler:
        container_name: querybook_scheduler
        image: *querybook-image
        tty: true
        stdin_open: true
        command: './querybook/scripts/runservice scheduler --pidfile="/opt/celerybeat.pid"'
        volumes: *querybook-volumes
        depends_on: *querybook-depends-on
    redis:
        container_name: querybook_redis
        image: redis:5.0.9
        restart: always
        command: ['redis-server', '--appendonly', 'yes']
        hostname: redis
        ports:
            - '6379:6379'
        healthcheck:
            test: ['CMD', 'redis-cli', 'ping']
            interval: 30s
            timeout: 10s
            retries: 3
#    mysql:
#        container_name: querybook_mysql
#        image: mysql:8.0
#        restart: always
#        ports:
#            # <Port exposed> : < MySQL Port running inside container>
#            - '3306:3306'
#        expose:
#            # Opens port 3306 on the container
#            - '3306'
#            # Where our data will be persisted
#        volumes:
#            - my-db:/var/lib/mysql
#        environment:
#            MYSQL_HOST: mysql:3306
#            MYSQL_DATABASE: querybook2
#            MYSQL_USER: test
#            MYSQL_PASSWORD: passw0rd
#            # Password for root access
#            MYSQL_ROOT_PASSWORD: hunter2
#        healthcheck:
#            test:
#                [
#                    'CMD-SHELL',
#                    "mysqladmin -h 'localhost' -u test -ppassw0rd ping --silent",
#                ]
#            interval: 30s
#            timeout: 30s
#            retries: 3
#        command: ['--character-set-server=utf8mb4', '--collation-server=utf8mb4_unicode_ci']
    elasticsearch:
        container_name: querybook_elasticsearch
        image: opensearchproject/opensearch:2.9.0
        environment:
            cluster.name: docker-cluster
            bootstrap.memory_lock: 'true'
            discovery.type: single-node
            plugins.security.disabled: 'true'
            OPENSEARCH_JAVA_OPTS: -Xms750m -Xmx750m
        ulimits:
            memlock:
                soft: -1
                hard: -1
            nofile:
                soft: 65536
                hard: 65536
        volumes:
            - osdata1:/usr/share/opensearch/data
        ports:
            - 9200:9200
        healthcheck:
            test:
                [
                    'CMD-SHELL',
                    'curl --silent --fail localhost:9200/_cluster/health || exit 1',
                ]
            interval: 30s
            timeout: 30s
            retries: 3

#    trino:
#        container_name: trino
#        image: trinodb/trino:latest
#        ports:
#            - '8089:8080'
#        networks:
#            - ailineage_network
#        volumes:
#            - ./docker-mount/trino/volume/catalog:/etc/trino/catalog
#            - ./docker-mount/trino/conf/etc/catalog/hive.properties:/etc/trino/catalog/hive.properties
#            - ./docker-mount/trino/conf/etc/config.properties:/etc/trino/config.properties
##            - ./docker-mount/trino/conf/etc/node.properties:/etc/trino/node.properties

#    postgres:
#        image: postgres
#        restart: unless-stopped
#        container_name: postgres
#        hostname: postgres
#        environment:
#            POSTGRES_DB: 'metastore_db'
#            POSTGRES_USER: 'hive'
#            POSTGRES_PASSWORD: 'password'
#        ports:
#            - '5432:5432'
#        volumes:
#            - ./docker-mount/postgres/data:/var/lib/postgresql
#        networks:
#            - ailineage_network
#    metastore:
#        image: apache/hive:4.0.0
#        depends_on:
#            - postgres
#        restart: unless-stopped
#        container_name: metastore
#        hostname: metastore
#        environment:
#            DB_DRIVER: postgres
#            SERVICE_NAME: 'metastore'
#            SERVICE_OPTS: '-Xmx1G -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver
#                         -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore_db
#                         -Djavax.jdo.option.ConnectionUserName=hive
#                         -Djavax.jdo.option.ConnectionPassword=password'
#        ports:
#            - '9083:9083'
#        volumes:
#            - ./docker-mount/hive/warehouse:/opt/hive/data/warehouse
#            - ./driver/postgresql-42.7.3.jar:/opt/hive/lib/postgres.jar
#        networks:
#            - ailineage_network
#    hiveserver2:
#            image: apache/hive:4.0.0
#            depends_on:
#                - metastore
#            restart: unless-stopped
#            container_name: hiveserver2
#            environment:
#                HIVE_SERVER2_THRIFT_PORT: 10000
#                SERVICE_OPTS: '-Xmx1G -Dhive.metastore.uris=thrift://metastore:9083'
#                IS_RESUME: 'true'
#                SERVICE_NAME: 'hiveserver2'
#            ports:
#                - '10000:10000'
#                - '10002:10002'
#            volumes:
#                - ./docker-mount/hive/warehouse:/opt/hive/data/warehouse
#            networks:
#                - ailineage_network
#    spark-master:
#        image: hackathron/spark-master:3.3.0-hadoop3.3
#        container_name: spark-master
#        ports:
#            - "8080:8080"
#            - "7077:7077"
#            - "10002:10001"
#        volumes:
#            - ./docker-mount/spark/hive-site.xml:/spark/conf/hive-site.xml
#            - ./docker-mount/spark/master.sh:/master.sh
#            - ./driver/hadoop-aws-3.3.2.jar:/spark/jars/hadoop-aws-3.3.2.jar
#            - ./driver/hadoop-aws-3.3.2.jar:/spark/jars/hadoop-aws-3.3.2.jar
#        environment:
#            - INIT_DAEMON_STEP=setup_spark
#    spark-worker-1:
#        image: bde2020/spark-worker:3.3.0-hadoop3.3
#        container_name: spark-worker-1
#        depends_on:
#            - spark-master
#        ports:
#            - "8081:8081"
#        environment:
#            - "SPARK_MASTER=spark://spark-master:7077"
#        volumes:
#            - ./docker-mount/spark/hive-site.xml:/spark/conf/hive-site.xml
#            - ./driver/hadoop-aws-3.3.2.jar:/spark/jars/hadoop-aws-3.3.2.jar
#    spark-worker-2:
#        image: bde2020/spark-worker:3.3.0-hadoop3.3
#        container_name: spark-worker-2
#        depends_on:
#            - spark-master
#        ports:
#            - "8082:8081"
#        environment:
#            - "SPARK_MASTER=spark://spark-master:7077"
#        volumes:
#            - ./docker-mount/spark/hive-site.xml:/spark/conf/hive-site.xml
#            - ./driver/hadoop-aws-3.3.2.jar:/spark/jars/hadoop-aws-3.3.2.jar
#    spark-history-server:
#        image: bde2020/spark-history-server:3.3.0-hadoop3.3
#        container_name: spark-history-server
#        depends_on:
#            - spark-master
#        ports:
#            - "18081:18081"
#        volumes:
#            - ./docker-mount/spark/hive-site.xml:/spark/conf/hive-site.xml
#            - ./driver/hadoop-aws-3.3.2.jar:/spark/jars/hadoop-aws-3.3.2.jar

    # EMAIL SERVER EXAMPLE
    # If you need email to work use this
    # dockerhostforward:
    #     expose:
    #         - '25'
    #     image: qoomon/docker-host
    #     cap_add: ['NET_ADMIN', 'NET_RAW']
    #     mem_limit: 8M
    #     restart: on-failure
    # CELERY FLOWER EXAMPLE
    # If you want flower monitoring, use this
    # Remember to put flower as part of local.txt
    # flower:
    #     image: querybook-dev:latest
    #     tty: true
    #     stdin_open: true
    #     # network_mode: "host"
    #     command: './querybook/scripts/runservice flower --port=5566'
    #     ports:
    #         - '5566:5566'
    #     expose:
    #         - '5566'
    #     restart: 'always'
    #     volumes:
    #         # This is for code change via watcher
    #         - $PWD:/opt/querybook
    #         - $PWD/containers/bundled_querybook_config.yaml:/opt/querybook/querybook/config/querybook_config.yaml
    #     depends_on:
    #         mysql:
    #             condition: service_healthy
    #         redis:
    #             condition: service_healthy

networks:
    ailineage_network:
        driver: bridge

volumes:
    my-db:
    osdata1:
        driver: local
    # file:
    #     driver: local
    #     driver_opts:
    #         type: 'none'
    #         o: 'bind'
    #         device: '/mnt/querybook-store/'
